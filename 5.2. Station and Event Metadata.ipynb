{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Obspy\n",
    "\n",
    "Obspy is the worldwide library for seismic data manipulation in Python. It includes nearly everything you need to work properly at the institute. \n",
    "\n",
    "If you want to search for something into Obspy, the website is really well documented [ObsPy Documentation](http://docs.obspy.org/) and you will find for sure the love of your life on it.\n",
    "\n",
    "Lesson based on [MESS 2014](https://github.com/obspy/mess2014-notebooks/) and [Seismo-Live](https://krischer.github.io/seismo_live_build/tree/index.html)\n",
    "\n",
    "The core functionality of ObsPy is provided by..\n",
    "\n",
    "- ..the most important base classes..\n",
    "  * the **`UTCDateTime`** class handles time information.\n",
    "  * the **`Stream`**/**`Trace`** classes handle waveform data.\n",
    "  * the **`Catalog`**/**`Event`**/... classes handle event metadata (modelled after QuakeML).\n",
    "  * the **`Inventory`**/**`Station`**/**`Response`**/... classes handle station metadata (modelled after FDSN StationXML).\n",
    "\n",
    "\n",
    "- ..and the associated functions:\n",
    "  * The **`read`** function. Reads all kinds of waveform file formats. Outputs a **`Stream`** object.\n",
    "  * The **`read_events`** function. Reads QuakeML (and MCHEDR) files. Outputs a **`Catalog`** object.\n",
    "  * The **`read_inventory`** function. Reads FDSN StationXML files. Outputs an **`Inventory`** object.\n",
    "\n",
    "\n",
    "- the most important classes/functions can be imported from main namespace (`from obspy import ...`)\n",
    "- Unified interface and functionality for handling waveform data regardless of data source\n",
    "- **`read`**, **`read_events`** and **`read_inventory`** functions access the appropriate file-format submodule/plugin using filetype autodiscovery\n",
    "- `obspy.core.util` includes some generally useful utility classes/functions (e.g. for geodetic calculations, Flinn-Engdahl regions, ..)\n",
    "- some convenience command line scripts are also included (e.g. `obspy-plot`, `obspy-print`, `obspy-scan`, ..)\n",
    "\n",
    "\n",
    "## 5.2. Station and Event Data\n",
    "\n",
    "### Station Data\n",
    "\n",
    "- for station metadata, the de-facto standard of the future (replacing SEED/RESP) is [FDSN StationXML](http://www.fdsn.org/xml/station/)\n",
    "- FDSN StationXML files can be read using **`read_inventory()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read_inventory\n",
    "# real-world StationXML files often deviate from the official schema definition\n",
    "# therefore file-format autodiscovery sometimes fails and we have to force the file format\n",
    "inventory = read_inventory(\"data/station_PFO.xml\", format=\"STATIONXML\")\n",
    "print(type(inventory))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the nested ObsPy Inventory class structure (Inventory/Station/Channel/Response/...) is closely modelled after FDSN StationXML\n",
    "<img src=\"images/Inventory.svg\" width=90%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = inventory[0]\n",
    "print(type(network))\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = network[0]\n",
    "print(type(station))\n",
    "print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = station[0]\n",
    "print(type(channel))\n",
    "print(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "st = read(\"data/waveform_PFO.mseed\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = read_inventory(\"data/station_PFO.xml\", format=\"STATIONXML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st[0].stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the instrument response can be deconvolved from the waveform data using the convenience method **`Stream.remove_response()`**\n",
    "- evalresp is used internally to calculate the instrument response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot()\n",
    "st.remove_response(inventory=inv)\n",
    "st.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- several options can be used to specify details of the deconvolution (water level, frequency domain prefiltering), output units (velocity/displacement/acceleration), demeaning, tapering and to specify if any response stages should be omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = read(\"data/waveform_PFO.mseed\")\n",
    "st.remove_response(inventory=inv, water_level=60, pre_filt=(0.01, 0.02, 8, 10), output=\"DISP\")\n",
    "st.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- station metadata not present in StationXML yet but in Dataless SEED or RESP files can be used for instrument correction using the `.simulate()` method of Stream/Trace in a similar fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Metadata\n",
    "\n",
    "- for event metadata, the de-facto standard is [QuakeML (an xml document structure)](https://quake.ethz.ch/quakeml/)\n",
    "- QuakeML files can be read using **`read_events()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read_events\n",
    "\n",
    "catalog = read_events(\"data/event_tohoku_with_big_aftershocks.xml\")\n",
    "print(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`read_events()`** function returns a **`Catalog`** object, which is\n",
    "a collection of **`Event`** objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(catalog))\n",
    "event = catalog[0]\n",
    "print(type(event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = catalog[0]\n",
    "\n",
    "print(event.picks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Event objects are again collections of other resources.\n",
    "- the nested ObsPy Event class structure (Catalog/Event/Origin/Magnitude/FocalMechanism/...) is closely modelled after QuakeML\n",
    "<img src=\"images/Event.svg\" width=90%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(event.origins))\n",
    "print(type(event.origins[0]))\n",
    "print(event.origins[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(event.magnitudes))\n",
    "print(type(event.magnitudes[0]))\n",
    "print(event.magnitudes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try event.<Tab> to get an idea what \"children\" elements event has"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Catalog object contains some convenience methods to make\n",
    "working with events easier.\n",
    "- for example, the included events can be filtered with various keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_magnitude_events = catalog.filter(\"magnitude >= 7.8\")\n",
    "print(largest_magnitude_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a basic preview plot using the matplotlib basemap module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.plot(projection=\"local\", outfile='data/catalog_plot.png') # cannot be done here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a (modified) Catalog can be output to file (currently there is write support for QuakeML only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_magnitude_events.write(\"data/large_events.xml\", format=\"QUAKEML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the event type classes can be used to build up Events/Catalogs/Picks/.. from scratch in custom processing work flows and to share them with other researchers in the de facto standard format QuakeML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "from obspy.core.event import Catalog, Event, Origin, Magnitude\n",
    "from obspy.geodetics import FlinnEngdahl\n",
    "\n",
    "cat = Catalog()\n",
    "cat.description = \"Just a fictitious toy example catalog built from scratch\"\n",
    "\n",
    "e = Event()\n",
    "e.event_type = \"not existing\"\n",
    "\n",
    "o = Origin()\n",
    "o.time = UTCDateTime(2014, 2, 23, 18, 0, 0)\n",
    "o.latitude = 47.6\n",
    "o.longitude = 12.0\n",
    "o.depth = 10000\n",
    "o.depth_type = \"operator assigned\"\n",
    "o.evaluation_mode = \"manual\"\n",
    "o.evaluation_status = \"preliminary\"\n",
    "o.region = FlinnEngdahl().get_region(o.longitude, o.latitude)\n",
    "\n",
    "m = Magnitude()\n",
    "m.mag = 7.2\n",
    "m.magnitude_type = \"Mw\"\n",
    "\n",
    "m2 = Magnitude()\n",
    "m2.mag = 7.4\n",
    "m2.magnitude_type = \"Ms\"\n",
    "\n",
    "# also included could be: custom picks, amplitude measurements, station magnitudes,\n",
    "# focal mechanisms, moment tensors, ...\n",
    "\n",
    "# make associations, put everything together\n",
    "cat.append(e)\n",
    "e.origins = [o]\n",
    "e.magnitudes = [m, m2]\n",
    "m.origin_id = o.resource_id\n",
    "m2.origin_id = o.resource_id\n",
    "\n",
    "print(cat)\n",
    "cat.write(\"data/my_custom_events.xml\", format=\"QUAKEML\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
