{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Obspy\n",
    "\n",
    "Obspy is the worldwide library for seismic data manipulation in Python. It includes nearly everything you need to work properly at the institute. \n",
    "\n",
    "If you want to search for something into Obspy, the website is really well documented [ObsPy Documentation](http://docs.obspy.org/) and you will find for sure the love of your life on it.\n",
    "\n",
    "Lesson based on [MESS 2014](https://github.com/obspy/mess2014-notebooks/) and [Seismo-Live](https://krischer.github.io/seismo_live_build/tree/index.html)\n",
    "\n",
    "The core functionality of ObsPy is provided by..\n",
    "\n",
    "- ..the most important base classes..\n",
    "  * the **`UTCDateTime`** class handles time information.\n",
    "  * the **`Stream`**/**`Trace`** classes handle waveform data.\n",
    "  * the **`Catalog`**/**`Event`**/... classes handle event metadata (modelled after QuakeML).\n",
    "  * the **`Inventory`**/**`Station`**/**`Response`**/... classes handle station metadata (modelled after FDSN StationXML).\n",
    "\n",
    "\n",
    "- ..and the associated functions:\n",
    "  * The **`read`** function. Reads all kinds of waveform file formats. Outputs a **`Stream`** object.\n",
    "  * The **`read_events`** function. Reads QuakeML (and MCHEDR) files. Outputs a **`Catalog`** object.\n",
    "  * The **`read_inventory`** function. Reads FDSN StationXML files. Outputs an **`Inventory`** object.\n",
    "\n",
    "\n",
    "- the most important classes/functions can be imported from main namespace (`from obspy import ...`)\n",
    "- Unified interface and functionality for handling waveform data regardless of data source\n",
    "- **`read`**, **`read_events`** and **`read_inventory`** functions access the appropriate file-format submodule/plugin using filetype autodiscovery\n",
    "- `obspy.core.util` includes some generally useful utility classes/functions (e.g. for geodetic calculations, Flinn-Engdahl regions, ..)\n",
    "- some convenience command line scripts are also included (e.g. `obspy-plot`, `obspy-print`, `obspy-scan`, ..)\n",
    "\n",
    "\n",
    "## 5.1. Handling Timestamps and File Format\n",
    "\n",
    "### Handling Timestamps\n",
    "\n",
    "This is a bit dry but not very difficult and important to know. It is used everywhere in ObsPy!\n",
    "\n",
    "\n",
    "* All absolute time values are consistently handled with this class\n",
    "* Based on a double precision POSIX timestamp for accuracy\n",
    "* Timezone can be specified at initialization (if necessary)\n",
    "* In Coordinated Universal Time (UTC) so no need to deal with timezones, daylight savings, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "\n",
    "print(UTCDateTime(\"2011-03-11T05:46:23.2\"))        # mostly time strings defined by ISO standard\n",
    "print(UTCDateTime(\"2011-03-11T14:46:23.2+09:00\"))  # non-UTC timezone input\n",
    "print(UTCDateTime(2011, 3, 11, 5, 46, 23, 200000))\n",
    "print(UTCDateTime(1299822383.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current time can be initialized by leaving out any arguments\n",
    "print(UTCDateTime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to access to the attributes of time :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = UTCDateTime()\n",
    "print(time.year)\n",
    "print(time.julday)\n",
    "print(time.timestamp)\n",
    "print(time.weekday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to now about all the attributes, you can press tab in the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do some operations with time, you have to use the second as the quantity. You can __add or substract__ seconds from one ``UTCDatetime`` object __BUT__ you can only do the __difference__ between two `UTCDateTime` objects.\n",
    "\n",
    "The result of the first one will be a __delta__ in seconds and the other will be an ``UTCDateTime`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time = UTCDateTime()\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2 = UTCDateTime()\n",
    "print(time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('time + 1 hour:', time + 3600) # one hour\n",
    "print('time - 1 hour:', time - 3600)\n",
    "print('Delta between time2 and time:', time2 - time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "t1 = UTCDateTime()\n",
    "sleep(5) # stop the script for 5 seconds\n",
    "t2 = UTCDateTime()\n",
    "\n",
    "print('t1:', t1, 'and t2:', t2)\n",
    "print('t1 + 1 hour:', t1 + 3600) # one hour\n",
    "print('t1 - 1 hour:', t1 - 3600)\n",
    "print('Delta between t2 and t1:', t2 - t1, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling File Format\n",
    "\n",
    "#### SEED Identifiers\n",
    "\n",
    "According to the  [SEED standard](www.fdsn.org/seed_manual/SEEDManual_V2.4.pdf), which is fairly well adopted, the following nomenclature is used to identify seismic receivers:\n",
    "\n",
    "* **Network code**: Identifies the network/owner of the data. Assigned by the FDSN and thus unique.\n",
    "* **Station code**: The station within a network. *NOT UNIQUE IN PRACTICE!* Always use together with a network code!\n",
    "* **Location ID**: Identifies different data streams within one station. Commonly used to logically separate multiple instruments at a single station.\n",
    "* **Channel codes**: Three character code: 1) Band and approximate sampling rate, 2) The type of instrument, 3) The orientation\n",
    "\n",
    "This results in full ids of the form **NET.STA.LOC.CHAN**, e.g. **RD.SONA0..SHZ**.\n",
    "\n",
    "In seismology we generally distinguish between three separate types of data:\n",
    "\n",
    "1. **Waveform Data** - The actual waveforms as time series.\n",
    "2. **Station Data** - Information about the stations' operators, geographical locations, and the instrument's responses.\n",
    "3. **Event Data** - Information about earthquakes.\n",
    "\n",
    "Some formats have elements of two or more of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waveform Data\n",
    "\n",
    "![stream](images/Stream_Trace.svg)\n",
    "\n",
    "There are a myriad of waveform data formats but in Europe and the USA two formats dominate: **MiniSEED** and **SAC**\n",
    "\n",
    "\n",
    "##### MiniSEED\n",
    "\n",
    "* This is what you get from datacenters and also what they store, thus the original data\n",
    "* Can store integers and single/double precision floats\n",
    "* Integer data (e.g. counts from a digitizer) are heavily compressed: a factor of 3-5 depending on the data\n",
    "* Can deal with gaps and overlaps\n",
    "* Multiple components per file\n",
    "* Contains only the really necessary parameters and some information for the data providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "\n",
    "# ObsPy automatically detects the file format.\n",
    "st = read(\"data/example.mseed\") # STREAM\n",
    "print(st)\n",
    "\n",
    "tr = st[0] # TRACE\n",
    "\n",
    "# Fileformat specific information is stored here.\n",
    "print(tr.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a quick interlude to teach you basics about how to work\n",
    "# with Stream/Trace objects.\n",
    "\n",
    "# We need to copy because some actions are modifying the original data\n",
    "st2 = st.copy()\n",
    "\n",
    "# To use only part of a Stream, use the select() function.\n",
    "st2 = st2.select(component=\"Z\")\n",
    "print(st2)\n",
    "\n",
    "# Stream objects behave like a list of Trace objects.\n",
    "tr = st2[0]\n",
    "print(tr.stats)\n",
    "tr.plot()\n",
    "\n",
    "# Some basic processing. Please note that these modify the\n",
    "# existing object.\n",
    "tr.detrend(\"linear\")\n",
    "tr.taper(type=\"hann\", max_percentage=0.05)\n",
    "tr.filter(\"lowpass\", freq=0.5)\n",
    "\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can write it again by simply specifing the format.\n",
    "st.write(\"temp.mseed\", format=\"mseed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SAC\n",
    "\n",
    "* Custom format of the `sac` code.\n",
    "* Simple header and single precision floating point data.\n",
    "* Only a single component per file and no concept of gaps/overlaps.\n",
    "* Used a lot due to `sac` being very popular and the additional basic information that can be stored in the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = obspy.read(\"data/example.sac\") + obspy.read(\"data/waveform_BFO_BHE.sac\")\n",
    "print(st)\n",
    "print(st[0].stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Station Data\n",
    "\n",
    "![inv](images/Inventory.svg)\n",
    "\n",
    "Station data contains information about the organziation that collections the data, geographical information, as well as the instrument response. It mainly comes in three formats:\n",
    "\n",
    "* `(dataless) SEED`: Very complete but pretty complex and binary. Still used a lot, e.g. for the Arclink protocol\n",
    "* `RESP`: A strict subset of SEED. ASCII based. Contains **ONLY** the response.\n",
    "* `StationXML`: Essentially like SEED but cleaner and based on XML. Most modern format and what the datacenters nowadays serve. **Use this if you can.**\n",
    "\n",
    "\n",
    "ObsPy can work with all of them but today we will focus on StationXML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are XML files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from obspy import read_inventory\n",
    "\n",
    "# Use the read_inventory function to open them.\n",
    "inv = read_inventory(\"data/all_stations.xml\")\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that they can contain an arbirary number of networks, stations, and channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# As well as a plot the instrument response.\n",
    "inv.select(network=\"IV\", station=\"SALO\", channel=\"BHZ\").plot_response(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of single channels can also be extraced. This function\n",
    "# also takes a datetime arguments to extract information at different\n",
    "# points in time.\n",
    "inv.get_coordinates(\"IV.SALO..BHZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And it can naturally be written again, also in modified state.\n",
    "inv.select(channel=\"BHZ\").write(\"data/temp.xml\", format=\"stationxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Data\n",
    "\n",
    "![events](./images/Event.svg)\n",
    "\n",
    "Event data is essentially served in either very simple formats like NDK or the CMTSOLUTION format used by many waveform solvers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datacenters on the hand offer QuakeML files, which are surprisingly complex in structure but can store complex relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read QuakeML files with the read_events() function.\n",
    "cat = obspy.read_events(\"data/GCMT_2014_04_01__Mw_8_1.xml\") + obspy.read_events(\"data/event_tohoku_mainshock.xml\")\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once again they can be written with the write() function.\n",
    "cat.write(\"data/temp_quake.xml\", format=\"quakeml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show off some more things, I added a file containing all events from 2014 in the GCMT catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat = obspy.read_events(\"data/2014.ndk\")\n",
    "\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat.plot() # doesn't work here, i don't have a map software on my server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.filter(\"magnitude > 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Waveform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "st = read(\"./data/waveform_PFO.mseed\", format=\"mseed\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- UNIX wildcards can be used to read multiple files simultaneously\n",
    "- automatic file format detection, no need to worry about file formats\n",
    "\n",
    "  - currently supported: **mseed, sac, segy, seg2, gse1/2, seisan, sh, datamark, css, wav, y, Q (keeps growing...)**\n",
    "  - more file formats are included whenever a basic reading routine is provided (or e.g. sufficient documentation on data compression etc.)\n",
    "  - custom user-specific file formats can be added (through plugin) to filetype autodiscovery in local ObsPy installation by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "st = read(\"./data/waveform_*\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for MiniSEED files, only reading short portions of files without all of the file getting read into memory is supported (saves time and memory when working on large collections of big files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "\n",
    "t = UTCDateTime(\"2011-03-11T05:46:23.015400Z\")\n",
    "st = read(\"./data/waveform_*\", starttime=t + 10 * 60, endtime=t + 12 * 60)\n",
    "print(st)\n",
    "st[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Stream Object\n",
    "\n",
    " - A Stream object is a collection of Trace objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "st = read(\"./data/waveform_PFO.mseed\")\n",
    "print(type(st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More traces can be assembled using **`+`** operator (or using the `.append()` and `.extend()` methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = read(\"./data/waveform_PFO.mseed\")\n",
    "st2 = read(\"./data/waveform_PFO_synthetics.mseed\")\n",
    "\n",
    "st = st1 + st2\n",
    "print(len(st), 'Traces')\n",
    "\n",
    "st3 = read(\"./data/waveform_BFO_BHE.sac\")\n",
    "\n",
    "st += st3\n",
    "print(len(st), 'Traces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - convenient (and nicely readable) looping over traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tr in st:\n",
    "    print(tr.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Stream is useful for applying the same processing to a larger number of different waveforms or to group Traces for processing (e.g. three components of one station in one Stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Trace Object\n",
    "\n",
    "- a Trace object is a single, contiguous waveform data block (i.e. regularly spaced time series, no gaps)\n",
    "- a Trace object contains a limited amount of metadata in a dictionary-like object (as **`Trace.stats`**) that fully describes the time series by specifying..\n",
    "  * recording location/instrument (network, station, location and channel code)\n",
    "  * start time\n",
    "  * sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = read(\"./data/waveform_PFO.mseed\")\n",
    "tr = st[0]  # get the first Trace in the Stream\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For custom applications it is sometimes necessary to directly manipulate the metadata of a Trace.\n",
    "- The metadata of the Trace will **stay consistent**, as all values are derived from the starttime, the data and the sampling rate and are **updated automatically**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.stats.delta, \"|\", tr.stats.endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.stats.sampling_rate = 5.0\n",
    "print(tr.stats.delta, \"|\", tr.stats.endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.stats.npts, \"|\", tr.stats.endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.data = tr.data[:100]\n",
    "print(tr.stats.npts, \"|\", tr.stats.endtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convenience methods make basic manipulations simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = read(\"./data/waveform_PFO.mseed\")[0]\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr)\n",
    "tr.resample(sampling_rate=100.0)\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr)\n",
    "tr.trim(tr.stats.starttime + 12 * 60, tr.stats.starttime + 14 * 60)\n",
    "print(tr)\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.detrend(\"linear\")\n",
    "tr.taper(max_percentage=0.05, type='cosine')\n",
    "tr.filter(\"lowpass\", freq=0.1)\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try tr.<Tab> for other methods defined for Trace\n",
    "tr.detrend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Raw data available as a [**`numpy.ndarray`**](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) (as **`Trace.data`**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.data[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data can be directly modified e.g. ..\n",
    "\n",
    "..by doing arithmetic operations (fast, handled in C by NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.data ** 2 + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..by using [**`numpy.ndarray`** builtin methods](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) (also done in C by NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr.data.max())\n",
    "print(tr.data.mean())\n",
    "print(tr.data.ptp())\n",
    "# try tr.data.<Tab> for a list of numpy methods defined on ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..by using **`numpy`** functions (also done in C by NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.abs(tr.data))\n",
    "# you can try np.<Tab> but there is a lot in there\n",
    "# try np.a<Tab>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..by feeding pointers to existing C/Fortran routines from inside Python!\n",
    "\n",
    "This is done internally in several places, e.g. for cross correlations, beamforming or in third-party filetype libraries like e.g. libmseed.\n",
    "\n",
    "- Trace objects can also be manually generated with data in a [**`numpy.ndarray`**](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) (e.g. when needing to parse waveforms from non-standard ascii files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import Trace\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.randint(-100, 100, 500)\n",
    "tr = Trace(data=x)\n",
    "tr.stats.station = \"XYZ\"\n",
    "tr.stats.starttime = UTCDateTime()\n",
    "\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stream objects can be assembled from manually generated Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import Stream\n",
    "\n",
    "tr2 = Trace(data=np.random.randint(-300, 100, 1000))\n",
    "tr2.stats.starttime = UTCDateTime()\n",
    "tr2.stats.sampling_rate = 10.0\n",
    "st = Stream([tr, tr2])\n",
    "\n",
    "st.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Builtin methods defined on **`Stream`** / **`Trace`**\n",
    "\n",
    "- Most methods that work on a Trace object also work on a Stream object. They are simply executed for every trace. [See ObsPy documentation for an overview of available methods](http://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.html) (or try **`st.<Tab>`**).\n",
    " - **`st.filter()`** - Filter all attached traces.\n",
    " - **`st.trim()`** - Cut all traces.\n",
    " - **`st.resample()`** / **`st.decimate()`** - Change the sampling rate.\n",
    " - **`st.trigger()`** - Run triggering algorithms.\n",
    " - **`st.plot()`** / **`st.spectrogram()`** - Visualize the data.\n",
    " - **`st.attach_response()`**/**`st.remove_response()`**, **`st.simulate()`** - Instrument correction\n",
    " - **`st.merge()`**, **`st.normalize()`**, **`st.detrend()`**, **`st.taper()`**, ...\n",
    "- A **`Stream`** object can also be exported to many formats, so ObsPy can be used to convert between different file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = read(\"./data/waveform_*.sac\")\n",
    "st.write(\"output_file.mseed\", format=\"MSEED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises about Timestamps\n",
    "\n",
    "Calculate the number of days passed since the Tohoku main shock (`2011-03-11T05:46:23.2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of 10 UTCDateTime objects, starting today at 10:00 with a spacing of 90 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "times = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of strings with origin times of magnitude 8+ earthquakes since 2000 (fetched from IRIS). Assemble a list of inter-event times in days. Use matplotlib to display a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [\"2001-06-23T20:33:09\",\n",
    "         \"2003-09-25T19:50:07\",\n",
    "         \"2004-12-23T14:59:00\",\n",
    "         \"2004-12-26T00:58:52\",\n",
    "         \"2005-03-28T16:09:35\",\n",
    "         \"2006-06-01T18:57:02\",\n",
    "         \"2006-06-05T00:50:31\",\n",
    "         \"2006-11-15T11:14:14\",\n",
    "         \"2007-01-13T04:23:23\",\n",
    "         \"2007-04-01T20:39:56\",\n",
    "         \"2007-08-15T23:40:58\",\n",
    "         \"2007-09-12T11:10:26\",\n",
    "         \"2009-09-29T17:48:11\",\n",
    "         \"2010-02-27T06:34:13\",\n",
    "         \"2011-03-11T05:46:23\",\n",
    "         \"2012-04-11T08:38:36\",\n",
    "         \"2012-04-11T10:43:10\",\n",
    "         \"2013-05-24T05:44:48\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace Exercises\n",
    " - Make an **`numpy.ndarray`** with zeros and (e.g. use **`numpy.zeros()`**) and put an ideal pulse somewhere in it\n",
    " - initialize a **`Trace`** object with your data array\n",
    " - Fill in some station information (e.g. network, station, ..)\n",
    " - Print trace summary and plot the trace\n",
    " - Change the sampling rate to 20 Hz\n",
    " - Change the starttime of the trace to the start time of this session\n",
    " - Print the trace summary and plot the trace again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from obspy import Trace, UTCDateTime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use **`tr.filter(...)`** and apply a lowpass filter with a corner frequency of 1 Hertz.\n",
    "- Display the preview plot, there are a few seconds of zeros that we can cut off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use **`tr.trim(...)`** to remove some of the zeros at start and at the end\n",
    "- show the preview plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scale up the amplitudes of the trace by a factor of 500\n",
    "- Add standard normal gaussian noise to the trace (use [**`np.random.randn()`**](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randn.html))\n",
    "- Display the preview plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Exercises\n",
    "\n",
    "- Read all Tohoku example earthquake data into a stream object (\"./data/waveform\\_\\*\")\n",
    "- Print the stream summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use **`st.select()`** to only keep traces of station BFO in the stream. Show the preview plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- trim the data to a 10 minute time window around the first arrival (just roughly looking at the preview plot)\n",
    "- display the preview plot and spectrograms for the stream (with logarithmic frequency scale, use `wlen=50` for the spectrogram plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove the linear trend from the data, apply a tapering and a lowpass at 0.1 Hertz\n",
    "- show the preview plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": false,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction about Timestamps\n",
    "\n",
    "Calculate the number of days passed since the Tohoku main shock (`2011-03-11T05:46:23.2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "nb_days = (UTCDateTime() - UTCDateTime(\"2011-03-11T05:46:23.200000Z\"))/86400\n",
    "print(round(nb_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of 10 UTCDateTime objects, starting today at 10:00 with a spacing of 90 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "current_time = UTCDateTime(\"2021-06-03T10:00:00.000000Z\")\n",
    "for i in range(0, 10):\n",
    "    times.append(current_time + 90*60*i)\n",
    "    \n",
    "print(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of strings with origin times of magnitude 8+ earthquakes since 2000 (fetched from IRIS). Assemble a list of inter-event times in days. Use matplotlib to display a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [\"2001-06-23T20:33:09\",\n",
    "         \"2003-09-25T19:50:07\",\n",
    "         \"2004-12-23T14:59:00\",\n",
    "         \"2004-12-26T00:58:52\",\n",
    "         \"2005-03-28T16:09:35\",\n",
    "         \"2006-06-01T18:57:02\",\n",
    "         \"2006-06-05T00:50:31\",\n",
    "         \"2006-11-15T11:14:14\",\n",
    "         \"2007-01-13T04:23:23\",\n",
    "         \"2007-04-01T20:39:56\",\n",
    "         \"2007-08-15T23:40:58\",\n",
    "         \"2007-09-12T11:10:26\",\n",
    "         \"2009-09-29T17:48:11\",\n",
    "         \"2010-02-27T06:34:13\",\n",
    "         \"2011-03-11T05:46:23\",\n",
    "         \"2012-04-11T08:38:36\",\n",
    "         \"2012-04-11T10:43:10\",\n",
    "         \"2013-05-24T05:44:48\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "interevent = []\n",
    "for i in range(0, len(times)-1):\n",
    "    interevent.append((UTCDateTime(times[i+1])-UTCDateTime(times[i]))/86400)\n",
    "print(interevent)\n",
    "\n",
    "plt.hist(interevent, bins=range(0, 1000, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace Correction\n",
    " - Make an **`numpy.ndarray`** with zeros and (e.g. use **`numpy.zeros()`**) and put an ideal pulse somewhere in it\n",
    " - initialize a **`Trace`** object with your data array\n",
    " - Fill in some station information (e.g. network, station, ..)\n",
    " - Print trace summary and plot the trace\n",
    " - Change the sampling rate to 20 Hz\n",
    " - Change the starttime of the trace to the start time of this session\n",
    " - Print the trace summary and plot the trace again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from obspy import Trace, UTCDateTime\n",
    "\n",
    "x = np.zeros(5000)\n",
    "x[2500] = 1.0\n",
    "\n",
    "tr = Trace(data=x)\n",
    "tr.stats.sampling_rate = 20.0\n",
    "\n",
    "tr.stats.network = 'IAG'\n",
    "tr.stats.station = 'TUNGA'\n",
    "tr.stats.channel = 'SHZ'\n",
    "\n",
    "starttime = UTCDateTime()\n",
    "\n",
    "tr.stats.starttime = starttime\n",
    "\n",
    "print(tr)\n",
    "tr.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use **`tr.filter(...)`** and apply a lowpass filter with a corner frequency of 1 Hertz.\n",
    "- Display the preview plot, there are a few seconds of zeros that we can cut off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "tr.filter(type='lowpass', freq=1.0)\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use **`tr.trim(...)`** to remove some of the zeros at start and at the end\n",
    "- show the preview plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "t1 = UTCDateTime(\"2021-06-17T04:03:00\")\n",
    "t2 = UTCDateTime(\"2021-06-17T04:03:15\")\n",
    "tr.trim(starttime=t1, endtime=t2)\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scale up the amplitudes of the trace by a factor of 500\n",
    "- Add standard normal gaussian noise to the trace (use [**`np.random.randn()`**](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randn.html))\n",
    "- Display the preview plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "tr.data *= 500\n",
    "tr.data = tr.data + np.random.randn(len(tr.data)) \n",
    "\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Correction\n",
    "\n",
    "- Read all Tohoku example earthquake data into a stream object (\"./data/waveform\\_\\*\")\n",
    "- Print the stream summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "\n",
    "st = read(\"./data/waveform_*\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use **`st.select()`** to only keep traces of station BFO in the stream. Show the preview plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "st = st.select(station='BFO')\n",
    "print(st)\n",
    "st.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- trim the data to a 10 minute time window around the first arrival (just roughly looking at the preview plot)\n",
    "- display the preview plot and spectrograms for the stream (with logarithmic frequency scale, use `wlen=50` for the spectrogram plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "\n",
    "st.trim(starttime=UTCDateTime(\"2011-03-11T05:55:00\"))\n",
    "\n",
    "st.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.spectrogram(log=True, wlen=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove the linear trend from the data, apply a tapering and a lowpass at 0.1 Hertz\n",
    "- show the preview plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": false,
    "tags": [
     "exercise"
    ]
   },
   "outputs": [],
   "source": [
    "st.detrend('linear')\n",
    "st.taper(type=\"hann\", max_percentage=0.05)\n",
    "st.filter(\"lowpass\", freq=0.1)\n",
    "st.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.spectrogram(log=True, wlen=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
